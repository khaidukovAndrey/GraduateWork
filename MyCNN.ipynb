{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bedd7592-f4c1-4365-9968-e80e7b9c2444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision as tv\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "8a7c1c39-b31c-4752-8786-933c03d8fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetToClass(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_dirs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.path_dirs = []\n",
    "        for i in path_dirs:\n",
    "            self.path_dirs.append(i)\n",
    "        \n",
    "        self.class_borders=[]\n",
    "        self.class_borders.append(0)\n",
    "        #print(sorted(os.listdir(path_dirs[0])))\n",
    "        self.dir_list=[]\n",
    "        for i in range(1, len(path_dirs)+1):\n",
    "            self.dir_list.append(sorted(os.listdir(path_dirs[i-1])))\n",
    "            self.class_borders.append(len(self.dir_list[i-1])+ self.class_borders[i-1])\n",
    "        #print(self.class_borders)\n",
    "    \n",
    "    def __len__(self):\n",
    "        length = 0\n",
    "        for i in self.dir_list:\n",
    "            length += len(i)\n",
    "        return length\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        class_id=0\n",
    "        for i in range(1,11):\n",
    "            if idx >= self.class_borders[i-1] and idx < self.class_borders[i]:\n",
    "                class_id = i-1\n",
    "                break\n",
    "        img_path = os.path.join(self.path_dirs[class_id], self.dir_list[class_id][self.class_borders[class_id]-idx])\n",
    "\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        img=img.astype(np.float32)\n",
    "        img = img/255.0\n",
    "        img = cv2.resize(img,(128,128), interpolation = cv2.INTER_AREA)\n",
    "        img = img.transpose((2,0,1))\n",
    "        t_img = torch.from_numpy(img)\n",
    "        t_class_id = torch.tensor(class_id)\n",
    "        #return img\n",
    "        return {'img': t_img, 'label':t_class_id}        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "1aa1573d-7834-4837-bfa3-3e574008822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = DatasetToClass([\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/1. Eczema 1677',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/2. Melanoma 15.75k',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/3. Atopic Dermatitis - 1.25k',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/4. Basal Cell Carcinoma (BCC) 3323',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/5. Melanocytic Nevi (NV) - 7970',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/6. Benign Keratosis-like Lesions (BKL) 2624',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/7. Psoriasis pictures Lichen Planus and related diseases - 2k',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/8. Seborrheic Keratoses and other Benign Tumors - 1.8k',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/9. Tinea Ringworm Candidiasis and other Fungal Infections - 1.7k',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/10. Warts Molluscum and other Viral Infections - 2103'\n",
    "])\n",
    "\n",
    "test_ds = DatasetToClass([\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/1. TEczema 1677',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/2. TMelanoma 15.75k',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/3. TAtopic Dermatitis - 1.25k',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/4. TBasal Cell Carcinoma (BCC) 3323',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/5. TMelanocytic Nevi (NV) - 7970',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/6. TBenign Keratosis-like Lesions (BKL) 2624',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/7. TPsoriasis pictures Lichen Planus and related diseases - 2k',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/8. TSeborrheic Keratoses and other Benign Tumors - 1.8k',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/9. TTinea Ringworm Candidiasis and other Fungal Infections - 1.7k',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/10. TWarts Molluscum and other Viral Infections - 2103'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "a65f7ead-9ff7-4738-972d-43cc5cfd7f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, shuffle = True, batch_size = batch_size, num_workers=1, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, shuffle = True, batch_size = batch_size, num_workers=1, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "968ed405-c4b0-4db6-9913-e3b29f7a06a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.act = nn.LeakyReLU(0.2)\n",
    "        self.maxpool = nn.MaxPool2d(2,2)\n",
    "        self.conv0 = nn.Conv2d(3, 32 , 3, stride=1, padding=0)\n",
    "        self.conv1 = nn.Conv2d(32, 32 , 3, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 64 , 3, stride=1, padding=0)\n",
    "        self.conv3 = nn.Conv2d(64, 128 , 3, stride=1, padding=0)\n",
    "\n",
    "        self.adaptivepool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(128,32)\n",
    "        self.linear2 = nn.Linear(32,10)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv0(x)\n",
    "        out = self.act(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.act(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.act(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.act(out)\n",
    "        \n",
    "        out = self.adaptivepool(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.linear1(out)\n",
    "        out = self.act(out)\n",
    "        out = self.linear2(out)\n",
    "        return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "82852ceb-ebee-4119-bc3d-e0f595220772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "55b76009-7052-42d6-9941-f3f625dcacd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "108b996b-40ac-4528-85e2-5ef2f59afc22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (act): LeakyReLU(negative_slope=0.2)\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (adaptivepool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear1): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (linear2): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "4d1924a5-a416-4da7-bc5b-350ad03c89c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106954"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "5329f3cd-5379-41c1-ac03-db1428358b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in train_loader:\n",
    "    img = sample['img']\n",
    "    label = sample['label']\n",
    "    model(img)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "ba6bbe96-b6d7-4a08-956e-e0108d48315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "e9ff85ee-d530-4d80-ab11-ee776fb0ee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, label):\n",
    "    answer = F.softmax(pred.detach()).numpy().argmax(1) == label.numpy().argmax(1) \n",
    "    return answer.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "baa28ba0-39f3-4580-bc30-77d779bec6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = 'cuda' # if torch.cuda.is_available() else 'cpu'\n",
    "#model = model.to(device)\n",
    "#loss_fn = loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "f00c4a62-b7eb-4412-a811-c1239a968a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use_amp = True\n",
    "#scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "acf4d25b-9ddc-466f-bb43-88c1c0d2c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.backends.cudnn.benchmark = True\n",
    "#torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "c660dff9-e1ab-412e-8924-50bdcfdd5fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1528"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "64e8d065-79be-49b7-ae22-a231f5704178",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/1528 [00:00<?, ?it/s]/tmp/ipykernel_893/156703249.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  answer = F.softmax(pred.detach()).numpy().argmax(1) == label.numpy().argmax(1)\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 1528/1528 [05:58<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.756192687840362\n",
      "0.37381380890052357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1528/1528 [05:29<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4971238950082144\n",
      "0.4565608638743455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1528/1528 [05:07<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3453545348026366\n",
      "0.49910013089005234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1528/1528 [05:08<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2123878315793282\n",
      "0.5391443062827225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1528/1528 [05:06<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1437140027577963\n",
      "0.5613956151832461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1528/1528 [05:05<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.093659412486391\n",
      "0.5813972513089005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1528/1528 [05:06<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0520027937728385\n",
      "0.5968586387434555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1528/1528 [05:05<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0227092187169022\n",
      "0.6085160340314136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▏                                                                              | 41/1528 [00:09<05:53,  4.21it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[269], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(img)\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, label)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m loss_item \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     19\u001b[0m loss_val \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_item\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_val = 0\n",
    "    acc_val = 0\n",
    "    for sample in (pbar := tqdm(train_loader)):\n",
    "        img, label = sample['img'], sample['label']\n",
    "        optimizer.zero_grad()\n",
    "        #img = img.to(device)\n",
    "        #label = label.to(device)\n",
    "        \n",
    "        label = F.one_hot(label, 10).float()\n",
    "        pred = model(img)\n",
    "        \n",
    "        loss = loss_fn(pred, label)\n",
    "\n",
    "        loss.backward()\n",
    "        loss_item = loss.item()\n",
    "        loss_val += loss_item\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        acc_current = accuracy(pred, label)\n",
    "        acc_val += acc_current\n",
    "\n",
    "    pbar.set_description(f'loss: {loss_item:.5f}\\taccuracy: {acc_current:.3f}')\n",
    "    print(loss_val/len(train_loader))\n",
    "    print(acc_val/len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab4fad-e148-49ef-b062-b03b5762461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_val = 0\n",
    "acc_val = 0\n",
    "for sample in (pbar := tqdm(test_loader)):\n",
    "    with torch.no_grad():\n",
    "        img, label = sample['img'], sample['label']\n",
    "\n",
    "        label = F.one_hot(label, 2).float()\n",
    "        pred = model(img)\n",
    "\n",
    "        loss = loss_fn(pred, label)\n",
    "        loss_item = loss.item()\n",
    "        loss_val += loss_item\n",
    "\n",
    "        acc_current = accuracy(pred, label)\n",
    "        acc_val += acc_current\n",
    "\n",
    "    pbar.set_description(f'loss: {loss_item:.5f}\\taccuracy: {acc_current:.3f}')\n",
    "print(loss_val/len(train_loader))\n",
    "print(acc_val/len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55c4b91-9b00-4f9c-9960-c87e989ae9e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
