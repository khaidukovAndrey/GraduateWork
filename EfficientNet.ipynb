{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8c8b3b2f-81d4-4a7c-8e1f-ffba81a56e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from math import ceil\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision as tv\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from evaluations.kaggle_2020 import global_average_precision_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "af7fe0d7-304c-418f-b35b-a0720c48c23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = [\n",
    "    #expand_ratio, channels, repeats, stride, kernel_size\n",
    "    [1,16,1,1,3],\n",
    "    [6,24,2,2,3],\n",
    "    [6,40,2,2,5],\n",
    "    [6,80,3,2,3],\n",
    "    [6,112,3,1,5],\n",
    "    [6,320,1,1,3]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c9bf30d9-bf60-4ae8-921b-ea238013f7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_values ={\n",
    "    #tuple of: (phi_value, resolution, drop_rate)\n",
    "    \"b0\": (0, 224, 0.2), #alpha, beta, gamma, depth = alpha**phi\n",
    "    \"b1\": (0.5, 240, 0.2),\n",
    "    \"b2\": (1, 260, 0.3),\n",
    "    \"b3\": (2, 300, 0.3),\n",
    "    \"b4\": (3, 380, 0.4),\n",
    "    \"b5\": (4, 456, 0.4),\n",
    "    \"b6\": (5, 528, 0.5),\n",
    "    \"b7\": (6, 600, 0.5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "15ee1c00-59a2-4508-bf52-b033f8ad6301",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.cnn = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride,\n",
    "            padding,\n",
    "            groups=groups,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.silu = nn.SiLU()\n",
    "    def forward(self, x):\n",
    "        return self.silu(self.bn(self.cnn(x)))\n",
    "\n",
    "class SqueezeExcitation(nn.Module):\n",
    "    def __init__(self, in_channels, reduced_dim):\n",
    "        super(SqueezeExcitation, self).__init__()\n",
    "        self.se = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_channels, reduced_dim, 1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(reduced_dim,in_channels,1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return x * self.se(x)\n",
    "\n",
    "class InvertedResidualBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        padding,\n",
    "        expand_ratio,\n",
    "        reduction=4, # squeeze excitation\n",
    "        survival_prob=0.8, # for stochastic depth\n",
    "    ):\n",
    "        super(InvertedResidualBlock, self).__init__()\n",
    "        self.survival_prob=0.8\n",
    "        self.use_residual = in_channels == out_channels and stride ==1\n",
    "        hidden_dim = in_channels * expand_ratio\n",
    "        self.expand = in_channels != hidden_dim\n",
    "        reduced_dim = int(in_channels/reduction)\n",
    "\n",
    "        if self.expand:\n",
    "            self.expand_conv = CNNBlock(\n",
    "                in_channels, hidden_dim, kernel_size=3, stride=1, padding=1,\n",
    "            )\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            CNNBlock(\n",
    "                hidden_dim, hidden_dim, kernel_size, stride, padding, groups=hidden_dim,\n",
    "            ),\n",
    "            SqueezeExcitation(hidden_dim, reduced_dim),\n",
    "            nn.Conv2d(hidden_dim, out_channels, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "    def stochastic_depth(self,x):\n",
    "        if not self.training:\n",
    "            return x\n",
    "        binary_tensor = torch.rand(x.shape[0], 1, 1, 1, device=x.device) < self.survival_prob\n",
    "        return torch.div(x, self.survival_prob) * binary_tensor\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.expand_conv(inputs) if self.expand else inputs\n",
    "\n",
    "        if self.use_residual:\n",
    "            return self.stochastic_depth(self.conv(x)) + inputs\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self, version, num_classes):\n",
    "        super(EfficientNet, self).__init__()\n",
    "        width_factor, depth_factor, dropout_rate = self.calculate_factors(version)\n",
    "        last_channels = ceil(1280 * width_factor)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.features = self.create_features(width_factor, depth_factor, last_channels)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(last_channels, num_classes),\n",
    "        )\n",
    "\n",
    "    def calculate_factors(self, version, alpha=1.2, beta=1.1):\n",
    "        phi, res, drop_rate = phi_values[version]\n",
    "        depth_factor = alpha ** phi\n",
    "        width_factor = beta ** phi\n",
    "        return width_factor, depth_factor, drop_rate\n",
    "\n",
    "    def create_features(self, width_factor, depth_factor, last_channels):\n",
    "        channels = int(32 * width_factor)\n",
    "        features = [CNNBlock(3, channels, 3, stride=2, padding=1)]\n",
    "        in_channels = channels\n",
    "        for expand_ratio, channels, repeats, stride, kernel_size in base_model:\n",
    "            out_channels = 4 * ceil(int(channels*width_factor)/4)\n",
    "            layers_repeats = ceil(repeats * depth_factor)\n",
    "            for layer in range(layers_repeats):\n",
    "                features.append(\n",
    "                    InvertedResidualBlock(\n",
    "                        in_channels,\n",
    "                        out_channels,\n",
    "                        expand_ratio=expand_ratio,\n",
    "                        stride = stride if layer == 0 else 1,\n",
    "                        kernel_size=kernel_size,\n",
    "                        padding=kernel_size//2,\n",
    "                    )\n",
    "                )\n",
    "                in_channels = out_channels\n",
    "        features.append(\n",
    "            CNNBlock(in_channels, last_channels, kernel_size=1, stride=1, padding=0)\n",
    "        )\n",
    "\n",
    "        return nn.Sequential(*features)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.pool(self.features(x))\n",
    "        return self.classifier(x.view(x.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c9bf147b-f4b1-4f61-b653-78de502ad3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetToClass(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_dirs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.path_dirs = []\n",
    "        for i in path_dirs:\n",
    "            self.path_dirs.append(i)\n",
    "        \n",
    "        self.class_borders=[]\n",
    "        self.class_borders.append(0)\n",
    "        #print(sorted(os.listdir(path_dirs[0])))\n",
    "        self.dir_list=[]\n",
    "        for i in range(1, len(path_dirs)+1):\n",
    "            self.dir_list.append(sorted(os.listdir(path_dirs[i-1])))\n",
    "            self.class_borders.append(len(self.dir_list[i-1])+ self.class_borders[i-1])\n",
    "        #print(self.class_borders)\n",
    "    \n",
    "    def __len__(self):\n",
    "        length = 0\n",
    "        for i in self.dir_list:\n",
    "            length += len(i)\n",
    "        return length\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        class_id=0\n",
    "        for i in range(1,11):\n",
    "            if idx >= self.class_borders[i-1] and idx < self.class_borders[i]:\n",
    "                class_id = i-1\n",
    "                break\n",
    "        img_path = os.path.join(self.path_dirs[class_id], self.dir_list[class_id][self.class_borders[class_id]-idx])\n",
    "\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        img=img.astype(np.float32)\n",
    "        img = img/255.0\n",
    "        img = cv2.resize(img,(128,128), interpolation = cv2.INTER_AREA)\n",
    "        img = img.transpose((2,0,1))\n",
    "        t_img = torch.from_numpy(img)\n",
    "        t_class_id = torch.tensor(class_id)\n",
    "        #return img\n",
    "        return {'img': t_img, 'label':t_class_id}        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2c65be0f-b7fc-4757-81ca-0625e3d2d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = DatasetToClass([\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/1. Eczema 1677',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/2. Melanoma 15.75k',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/3. Atopic Dermatitis - 1.25k',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/4. Basal Cell Carcinoma (BCC) 3323',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/5. Melanocytic Nevi (NV) - 7970',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/6. Benign Keratosis-like Lesions (BKL) 2624',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/7. Psoriasis pictures Lichen Planus and related diseases - 2k',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/8. Seborrheic Keratoses and other Benign Tumors - 1.8k',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/9. Tinea Ringworm Candidiasis and other Fungal Infections - 1.7k',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/10. Warts Molluscum and other Viral Infections - 2103'\n",
    "])\n",
    "\n",
    "test_ds = DatasetToClass([\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/1. TEczema 1677',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/2. TMelanoma 15.75k',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/3. TAtopic Dermatitis - 1.25k',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/4. TBasal Cell Carcinoma (BCC) 3323',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/5. TMelanocytic Nevi (NV) - 7970',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/6. TBenign Keratosis-like Lesions (BKL) 2624',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/7. TPsoriasis pictures Lichen Planus and related diseases - 2k',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/8. TSeborrheic Keratoses and other Benign Tumors - 1.8k',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/9. TTinea Ringworm Candidiasis and other Fungal Infections - 1.7k',\n",
    "    '/home/andrey/GraduateWork/IMG_CLASSES/10. TWarts Molluscum and other Viral Infections - 2103'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5c392250-b7eb-4384-b17b-9cf7ccacb03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 96\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, shuffle = True, batch_size = batch_size, num_workers=1, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, shuffle = True, batch_size = batch_size, num_workers=1, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7c826808-145f-4ca3-b5b9-05432e57919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "version = \"b4\"\n",
    "num_classes = 10\n",
    "model = EfficientNet(\n",
    "    version=version,\n",
    "    num_classes=num_classes,\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c206b7b3-f9e7-437c-8cd9-66055418d0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, betas=(0.9,0.999), eps=1e-3, weight_decay=1e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader), eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d70c675d-6c6c-4883-8e33-3b732b005631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GAP( y_true,y_pred):\n",
    "    return global_average_precision_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "90f8e614-bc91-4d95-af79-bc6b87ebeaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, label):\n",
    "    answer = F.softmax(pred.detach()).numpy().argmax(1) == label.numpy().argmax(1) \n",
    "    return answer.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0cde3fa9-dc49-4123-9912-cd330bef7949",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_amp = True\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "117cd79a-ba72-4352-8427-aadac61dc83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "da8cef6b-07c9-47b5-b80b-99db1753b276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/254 [01:04<?, ?it/s]Traceback (most recent call last):\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, label)  \n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#conf_scores, pred_labels = torch.max(yhat.detach(), dim=1)\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m loss_item \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     28\u001b[0m loss_val \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_item\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "loss_list = []\n",
    "#activation = nn.Softmax(dim=1)\n",
    "loss_list=[]\n",
    "gap_score_list=[]\n",
    "model.train()\n",
    "for epochs in range(n_epochs):\n",
    "    loss_val = 0\n",
    "    acc_val = 0\n",
    "    for sample in (pbar:=tqdm(train_loader)):        \n",
    "        img=sample['img']\n",
    "        label=sample['label']  \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        label = F.one_hot(label, 10).float()\n",
    "        img=img.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        with autocast(use_amp):\n",
    "            pred = model(img)\n",
    "            loss = loss_fn(pred, label)  \n",
    "        \n",
    "        #conf_scores, pred_labels = torch.max(yhat.detach(), dim=1)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        loss_item = loss.item()\n",
    "        loss_val += loss_item\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        acc_current = accuracy(pred.cpu().float(), label.cpu().float())\n",
    "        acc_val += acc_current\n",
    "\n",
    "        \n",
    "    pbar.set_description(f'loss: {loss_item:.5f}\\taccuracy: {acc_current:.3f}')\n",
    "    print(loss_val/len(train_loader))\n",
    "    print(acc_val/len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "58dde55a-40f5-474b-add1-0889138c8c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/29 [00:00<?, ?it/s]/tmp/ipykernel_491/156703249.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  answer = F.softmax(pred.detach()).numpy().argmax(1) == label.numpy().argmax(1)\n",
      "loss: 1.35449\taccuracy: 0.533: 100%|████████████████████████████████████████████████████| 29/29 [00:39<00:00,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9802288022534601\n",
      "0.6125000000000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_val = 0\n",
    "acc_val = 0\n",
    "for sample in (pbar := tqdm(test_loader)):\n",
    "    with torch.no_grad():\n",
    "        img, label = sample['img'], sample['label']\n",
    "\n",
    "        label = F.one_hot(label, 10).float()\n",
    "        img=img.to(device)\n",
    "        label = label.to(device)\n",
    "        pred = model(img)\n",
    "\n",
    "        loss = loss_fn(pred, label)\n",
    "        loss_item = loss.item()\n",
    "        loss_val += loss_item\n",
    "\n",
    "        acc_current = accuracy(pred.cpu().float(), label.cpu().float())\n",
    "        acc_val += acc_current\n",
    "\n",
    "    pbar.set_description(f'loss: {loss_item:.5f}\\taccuracy: {acc_current:.3f}')\n",
    "print(loss_val/len(test_loader))\n",
    "print(acc_val/len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362ff86f-fa61-4c58-a8a7-54940e69b6d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
